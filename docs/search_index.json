[
["index.html", "Data analysis and R programming Chapter 1 Preface 1.1 Installation 1.2 License", " Data analysis and R programming Laurent Gatto 2017-11-02 Chapter 1 Preface The material can be accessed here: https://lgatto.github.io/2017_11_09_Rcourse_Jena/ The source code for this document is available on GitHub at https://github.com/lgatto/2017_11_09_Rcourse_Jena. 1.1 Installation We will install required packages as we go along. Before the course, participants should install a recent version of R (ideally the current release version) and RStudio, or any other editor of their choice. 1.2 License This material is licensed under the Creative Commons Attribution-ShareAlike 3.0 License. Some content is inspired by other sources though, see the Credit section in the material. "],
["introduction.html", "Chapter 2 Introduction Programme", " Chapter 2 Introduction This course presents a 2-day introduction to data analysis and visualisation with R as well as certain programming topics. It is formatted as a bookdown document Programme Day 1 Setup and introduction Spreadsheets and tidy data (1 hour) Data manipulation using the tidyverse (1.5 hours) Visualisation with ggplot2 (1.5 hours) Wrap-up Day 2 Reproducible research with Rmarkdown (1 hour) R package development (about 1.5 hours) Viz. of high-dimensional data (bit.ly/highdimvis) (1.5 hours) Interactive visualisation: ggvis, shiny (1.5 hours) Navigate and mine Bioconductor for useful scripting components (0.5 hour) Wrap-up "],
["r-package-development.html", "Chapter 3 R Package Development 3.1 Introduction 3.2 Preparing R code 3.3 Package layout 3.4 Package developement cycle 3.5 Package metadata 3.6 NAMESPACE 3.7 R code 3.8 Package sub-directories 3.9 Documentation 3.10 Manual pages 3.11 Additional files 3.12 Distributing packages", " Chapter 3 R Package Development This section is based on material from the https://github.com/lgatto/RPackageDevelopment course. 3.1 Introduction Packages are the way to share R code in a structures, reproducible and tractable way. Even if the intend is not to disseminate your code, packaging it is worth it. Packages provide a mechanism for loading optional code and attached documentation as needed. logically group your own functions keep code and documentation together and consistent keep code and data together keep track of changes in code summarise all packages used for a analysis (see sessionInfo()) make a reproducible research compendium (container for code, text, data as a means for distributing, managing and updating) optionally test your code … project managment 3.1.1 References R packages, by Hadley Wickham R Installation and Administration [R-admin], R Core team Writing R Extensions [R-ext], R Core team Use help.start() to access them from your local installation, or http://cran.r-project.org/manuals.html from the web. 3.1.2 Terminology A package is loaded from a library by the function library(). Thus a library is a directory containing installed packages. Calling library(&quot;foo&quot;, lib.loc = &quot;/path/to/bar&quot;) loads the package (book) foo from the library bar located at /path/to/bar. 3.1.3 Requirement library(&quot;devtools&quot;) library(&quot;roxygen2&quot;) 3.1.4 Course content Basic workflow Prepare R code Create package directory: mypackage Build the package tarball Check the package Install the package Step 2 is done only once. Package developement cycles through 3 - 5. Also - Writing package documentation - Vignettes - Testing packages - Compiled code 3.2 Preparing R code fn &lt;- function() message(&quot;I love R packages&quot;) 3.3 Package layout We can use package.skeleton(&quot;myRpackage&quot;, list = &quot;fn&quot;) devtools::create(&quot;myRpackage&quot;) also create an .Rproj file. Use the RStudio wizard: New Project &gt; New Directory &gt; R Package myRpackage/ |-- DESCRIPTION |-- NAMESPACE |-- man | `-- fun.Rd `-- R `-- fun.R This is the source package. From this, we need to create the package tarball (or package bundle), i.e. a compressed archive of the source. We can also create binary packages for Windows and Mac. 3.4 Package developement cycle In the shell R CMD build myPackage ## creates myRpackage_1.0.tar.gz R CMD check myPackage_1.0.tar.gz ## create myRpackage.Rcheck R CMD INSTALL myRpackage_1.0.tar.gz ## Installation in the default library Using RStudio useful keyboard shortcuts for package authoring: Build and Reload Package: Ctrl + Shift + B Check Package: Ctrl + Shift + E Test Package: Ctrl + Shift + T Using devtools: * devtools::build() * devtools::build(binary = TRUE) * devtools::check() * devtools::install() A shortcut when developing: devtools::load_all() 3.5 Package metadata The DESCRIPTION file Package: myRpackage ## mandatory (*) Type: Package ## optional, &#39;Package&#39; is default type Title: What the package does (short line) ## * Version: 1.0 ## * Date: 2013-05-10 ## release date of the current version Author: Who wrote it ## * Maintainer: Who to complain to &lt;yourfault@somewhere.net&gt; ## * Description: More about what it does (maybe more than one line) ## * License: What license is it under? ## * Depends: methods, Biostrings ## for e.g. Imports: evd ## for e.g. Suggests: BSgenome.Hsapiens.UCSC.hg19 ## for e.g. Collate: &#39;DataClasses.R&#39; &#39;read.R&#39; ## for e.g. Package dependencies: Depends A comma-separated list of package names (optionally with versions) which this package depends on. Suggests Packages that are not necessarily needed: used only in examples, tests or vignettes, loaded in the body of functions Imports Packages whose name spaces are imported from (as specified in the NAMESPACE file) which do not need to be attached to the search path. Collate Controls the collation order for the R code files in a package. If filed is present, all source files must be listed. Packages are attached to the search path with or . Attach When a package is attached, then all of its dependencies (see Depends field in its DESCRIPTION file) are also attached. Such packages are part of the evaluation environment and will be searched. Load One can also use the Imports field in the NAMESPACE file. Imported packages are loaded but are not attached: they do not appear on the search path and are available only to the package that imported them. 3.6 NAMESPACE Restricts the symbols that are exported and imports functionality from other packages. Only the exported symbols will have to be documented. export(f, g) ## exports f and g exportPattern(&quot;^[^\\\\.]&quot;) import(foo) ## imports all symbols from package foo importFrom(foo, f, g) ## imports f and g from foo It is possible to explicitely use symbol s from package foo with foo::s or foo:::s if s is not exported. 3.7 R code Contains source()able R source code to be installed. Files must start with an ASCII (lower or upper case) letter or digit and have one of the extensions .R, .S, .q, .r, or .s (use .R or .r). General style guidelines and best practice apply. Any number of files in R. Any number of functions (methods, classes) in each source file. Order matters (somehow), as the files will be sourced in the alphanumeric order. If that doesn’t fit, use the collate field in the DESCRIPTION files. Example ## works fine without Collate field AllGenerics.R DataClasses.R methods-ClassA.R methods-ClassB.R functions-ClassA.R ... zzz.R is generally used to define special functions used to initialize (called after a package is loaded and attached) and clean up (just before the package is detached). See help(&quot;.onLoad&quot;)), ?.First.Lib and ?.Last.Lib for more details. 3.8 Package sub-directories vignettes directory for vignettes in Sweave or R markdown format. data for R code, compressed tables (.tab, .txt, or .csv, see ?data for the file formats) and binary R objects. Available with data(). inst/docs for additional documentation. That’s also where the vignettes will be installed after compilation. inst/extdata directory for other data files, not belonging in data. tests code for unit tests (see here and here). src for compiled code (see the rccpp material) demo for demo code (see ?demo) 3.9 Documentation 3.10 Manual pages Package functions, datasets, methods and classes are documented in Rd, a LaTeX-like format. % File src/library/base/man/load.Rd % Part of the R package, http://www.R-project.org % Copyright 1995-2014 R Core Team % Distributed under GPL 2 or later \\name{load} \\alias{load} \\title{Reload Saved Datasets} \\description{ Reload datasets written with the function \\code{save}. } \\usage{ load(file, envir = parent.frame(), verbose = FALSE) } \\arguments{ \\item{file}{a (readable binary-mode) \\link{connection} or a character string giving the name of the file to load (when \\link{tilde expansion} is done).} \\item{envir}{the environment where the data should be loaded.} \\item{verbose}{should item names be printed during loading?} } \\details{ \\code{load} can load \\R objects saved in the current or any earlier format. It can read a compressed file (see \\code{\\link{save}}) directly from a file or from a suitable connection (including a call to \\code{\\link{url}}). [...] \\value{ A character vector of the names of objects created, invisibly. } \\section{Warning}{ Saved \\R objects are binary files, even those saved with \\code{ascii = TRUE}, so ensure that they are transferred without conversion of end of line markers. \\code{load} tries to detect such a conversion and gives an informative error message. [...] \\examples{ ## save all data xx &lt;- pi # to ensure there is some data save(list = ls(all = TRUE), file= &quot;all.RData&quot;) rm(xx) ## restore the saved values to the current environment local({ load(&quot;all.RData&quot;) ls() }) xx &lt;- exp(1:3) ## restore the saved values to the user&#39;s workspace load(&quot;all.RData&quot;) ## which is here *equivalent* to ## load(&quot;all.RData&quot;, .GlobalEnv) ## This however annihilates all objects in .GlobalEnv with the same names ! xx # no longer exp(1:3) rm(xx) attach(&quot;all.RData&quot;) # safer and will warn about masked objects w/ same name in .GlobalEnv ls(pos = 2) ## also typically need to cleanup the search path: detach(&quot;file:all.RData&quot;) ## clean up (the example): unlink(&quot;all.RData&quot;) \\dontrun{ con &lt;- url(&quot;http://some.where.net/R/data/example.rda&quot;) ## print the value to see what objects were created. print(load(con)) close(con) # url() always opens the connection }} \\keyword{file} These R documentation files can then be converted into text, pdf or html: help(&quot;load&quot;) help(&quot;load&quot;, help_type = &quot;html&quot;) help(&quot;load&quot;, help_type = &quot;pdf&quot;) One can use prompt, promptClass, promptMethods, promptPackage, promptPackage, promptData to generate Rd templates for functions, classes, methods, packages and data. 3.10.1 Use roxygen The way documentation is managed in R packages separates the code from the documentation, which makes it easier to adapt the latter when to code is updated. In comes roxygen2, that allows developer to write their documentation on top of their functions: #&#39; Reads sequences data in fasta and create \\code{DnaSeq} #&#39; and \\code{RnaSeq} instances. #&#39; #&#39; This funtion reads DNA and RNA fasta files and generates #&#39; valid \\code{&quot;DnaSeq&quot;} and \\code{&quot;RnaSeq&quot;} instances. #&#39; #&#39; @title Read fasta files. #&#39; @param infile the name of the fasta file which the data are to be read from. #&#39; @return an instance of \\code{DnaSeq} or \\code{RnaSeq}. #&#39; @seealso \\code{\\linkS4class{GenericSeq}}, \\code{\\linkS4class{DnaSeq}} and \\code{\\linkS4class{RnaSeq}}. #&#39; @examples #&#39; f &lt;- dir(system.file(&quot;extdata&quot;,package=&quot;sequences&quot;),pattern=&quot;fasta&quot;,full.names=TRUE) #&#39; f #&#39; aa &lt;- readFasta(f) #&#39; aa #&#39; @author Laurent Gatto \\email{lg390@@cam.ac.uk} #&#39; @export readFasta &lt;- function(infile){ lines &lt;- readLines(infile) header &lt;- grep(&quot;^&gt;&quot;, lines) if (length(header)&gt;1) { warning(&quot;Reading first sequence only.&quot;) lines &lt;- lines[header[1]:(header[2]-1)] header &lt;- header[1] } ##### (code cut for space reasons) ##### if (validObject(newseq)) return(newseq) } The roxygen code can then be parsed and converted to Rd using the roxygen2::roxygenise or devtools::document functions. Note that the roxygenise function does more than produce documentation (that part is handled by the rd roclet, set with roclet = &quot;rd&quot;). It can also manage your NAMESPACE file and Collate field. Note: recently, support for markdown format has been added to roxygen. 3.10.2 Vignettes While manual pages are meant to be specific and technical, vignettes are workflow-type documentation files that provide an overview and/or a use-case demonstrating the package’s functionality. Vignettes can be written in Sweave format (.Rnw extension), supporting R code chunks in LaTeX documents, or R markdown formart (.Rmd extension) for R code and markdown. The source document (.Rnw or .Rmd) can be weaved into tex or md files respectively and converted into pdf or html (Rnw to pdf only, Rmd to either) using the utils::Sweave (Rnw only) or knitr::knit functions. Rstudio makes it very easy to write and compile Rmd documents (independently of R packages). When inside a package, the documents are stored in the vignettes directory and compiled/converted automatically when the package is built. Note: if you use knitr and rmarkdown for your vignette, you’ll have to add these dependencies in the Suggests field and specify VignetteBuilder: knitr in the DESCRIPTION file. 3.11 Additional files .Rbuildignore with a list of files/dirs to ignore when building. For example the .Rproj file. .Rinstignorewith a list of files/dirs to ignore when installing. CITATION file (see citation() function) README.Rmd/README.md files if you use github. 3.12 Distributing packages CRAN Read the CRAN Repository Policy (http://cran.r-project.org/web/packages/policies.html). Upload your --as-cran checked} myPackage\\_x.y.z.tar.gz to ftp://cran.R-project.org/incoming or using http://CRAN.R-project.org/submit.html. Your package will be installable with install.packages(&quot;myRpackage&quot;). R-forge Log in, register a project and wait for acceptance. Then commit you code to the svn repository. Your package will be installable with install.packages using repos=&quot;http://R-Forge.R-project.org&quot;. GitHub (and Bitbucket) Great for development and promoting interaction and contributions. Unofficial. Autmatic checking possible through CI such as travis-ci for example. Packages can be installed with devtools::install_github (devtools::install_bitbucket). Bioconductor Make sure to satisfy submission criteria (pass check (and BiocCheck), have a vignette, use S4 if OO, make use of appropriate existing infrastructure, include a NEWS file, must not already be on CRAN, …). Your package will then be reviewed on github publicly before acceptance. A svn (git very soon) account will then be created. Package will be installable with biocLite(&quot;myPackage&quot;). "],
["visualisation-of-high-dimensional-data-in-r.html", "Chapter 4 Visualisation of high-dimensional data in R 4.1 Introduction 4.2 Data 4.3 K-means clustering 4.4 Hierarchical clustering 4.5 Principal component analysis (PCA)", " Chapter 4 Visualisation of high-dimensional data in R This section is based composed of the Visualisation of high-dimensional data presentation, and parts of the Introduction to Machine Learning with R course (unsupervised learning chapter). 4.1 Introduction Visualisation of high-dimensional data slides. 4.2 Data To illustrate some visualisation techniques, we are going to make use of Edgar Anderson’s Iris Data, available in R with data(iris) From the iris manual page: This famous (Fisher’s or Anderson’s) iris data set gives the measurements in centimeters of the variables sepal length and width and petal length and width, respectively, for 50 flowers from each of 3 species of iris. The species are Iris setosa, versicolor, and virginica. For more details, see ?iris. 4.3 K-means clustering The k-means clustering algorithms aims at partitioning n observations into a fixed number of k clusters. The algorithm will find homogeneous clusters. In R, we use stats::kmeans(x, centers = 3, nstart = 10) where x is a numeric data matrix centers is the pre-defined number of clusters the k-means algorithm has a random component and can be repeated nstart times to improve the returned model Challenge: To learn about k-means, let’s use the iris with the sepal and petal length variables only (to facilitate visualisation). Create such a data matrix and name it x Run the k-means algorithm on the newly generated data x, save the results in a new variable cl, and explore its output when printed. The actual results of the algorithms, i.e. the cluster membership can be accessed in the clusters element of the clustering result output. Use it to colour the inferred clusters to generate a figure like shown below. Figure 4.1: k-means algorithm on sepal and petal lengths i &lt;- grep(&quot;Length&quot;, names(iris)) x &lt;- iris[, i] cl &lt;- kmeans(x, 3, nstart = 10) plot(x, col = cl$cluster) 4.3.1 How does k-means work Initialisation: randomly assign class membership Figure 4.2: k-means random intialisation Iteration: Calculate the centre of each subgroup as the average position of all observations is that subgroup. Each observation is then assigned to the group of its nearest centre. It’s also possible to stop the algorithm after a certain number of iterations, or once the centres move less than a certain distance. Figure 4.3: k-means iteration: calculate centers (left) and assign new cluster membership (right) Termination: Repeat iteration until no point changes its cluster membership. k-means convergence (credit Wikipedia) 4.3.2 Model selection Due to the random initialisation, one can obtain different clustering results. When k-means is run multiple times, the best outcome, i.e. the one that generates the smallest total within cluster sum of squares (SS), is selected. The total within SS is calculated as: For each cluster results: for each observation, determine the squared euclidean distance from observation to centre of cluster sum all distances Note that this is a local minimum; there is no guarantee to obtain a global minimum. Challenge: Repeat kmeans on our x data multiple times, setting the number of iterations to 1 or greater and check whether you repeatedly obtain the same results. Try the same with random data of identical dimensions. cl1 &lt;- kmeans(x, centers = 3, nstart = 10) cl2 &lt;- kmeans(x, centers = 3, nstart = 10) table(cl1$cluster, cl2$cluster) ## ## 1 2 3 ## 1 58 0 0 ## 2 0 41 0 ## 3 0 0 51 cl1 &lt;- kmeans(x, centers = 3, nstart = 1) cl2 &lt;- kmeans(x, centers = 3, nstart = 1) table(cl1$cluster, cl2$cluster) ## ## 1 2 3 ## 1 0 0 41 ## 2 0 51 0 ## 3 58 0 0 set.seed(42) xr &lt;- matrix(rnorm(prod(dim(x))), ncol = ncol(x)) cl1 &lt;- kmeans(xr, centers = 3, nstart = 1) cl2 &lt;- kmeans(xr, centers = 3, nstart = 1) table(cl1$cluster, cl2$cluster) ## ## 1 2 3 ## 1 46 0 6 ## 2 1 51 0 ## 3 0 1 45 diffres &lt;- cl1$cluster != cl2$cluster par(mfrow = c(1, 2)) plot(xr, col = cl1$cluster, pch = ifelse(diffres, 19, 1)) plot(xr, col = cl2$cluster, pch = ifelse(diffres, 19, 1)) Figure 4.4: Different k-means results on the same (random) data 4.3.3 How to determine the number of clusters Run k-means with k=1, k=2, …, k=n Record total within SS for each value of k. Choose k at the elbow position, as illustrated below. Challenge Calculate the total within sum of squares for k from 1 to 5 for our x test data, and reproduce the figure above. ks &lt;- 1:5 tot_within_ss &lt;- sapply(ks, function(k) { cl &lt;- kmeans(x, k, nstart = 10) cl$tot.withinss }) plot(ks, tot_within_ss, type = &quot;b&quot;) 4.4 Hierarchical clustering 4.4.1 How does hierarchical clustering work Initialisation: Starts by assigning each of the n point its own cluster Iteration Find the two nearest clusters, and join them together, leading to n-1 clusters Continue merging cluster process until all are grouped into a single cluster Termination: All observations are grouped within a single cluster. Figure 4.5: Hierarchical clustering: initialisation (left) and colour-coded results after iteration (right). The results of hierarchical clustering are typically visualised along a dendrogram, where the distance between the clusters is proportional to the branch lengths. Figure 4.6: Visualisation of the hierarchical clustering results on a dendrogram In R: Calculate the distance using dist, typically the Euclidean distance. Hierarchical clustering on this distance matrix using hclust Challenge Apply hierarchical clustering on the iris data and generate a dendrogram using the dedicated plot method. d &lt;- dist(iris[, 1:4]) hcl &lt;- hclust(d) hcl ## ## Call: ## hclust(d = d) ## ## Cluster method : complete ## Distance : euclidean ## Number of objects: 150 plot(hcl) 4.4.2 Defining clusters After producing the hierarchical clustering result, we need to cut the tree (dendrogram) at a specific height to defined the clusters. For example, on our test dataset above, we could decide to cut it at a distance around 1.5, with would produce 2 clusters. Figure 4.7: Cutting the dendrogram at height 1.5. In R we can us the cutree function to cut the tree at a specific height: cutree(hcl, h = 1.5) cut the tree to get a certain number of clusters: cutree(hcl, k = 2) Challenge Cut the iris hierarchical clustering result at a height to obtain 3 clusters by setting h. Cut the iris hierarchical clustering result at a height to obtain 3 clusters by setting directly k, and verify that both provide the same results. plot(hcl) abline(h = 3.9, col = &quot;red&quot;) cutree(hcl, k = 3) ## [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [36] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 3 2 3 2 3 2 3 3 3 3 2 3 2 3 3 2 3 ## [71] 2 3 2 2 2 2 2 2 2 3 3 3 3 2 3 2 2 2 3 3 3 2 3 3 3 3 3 2 3 3 ## [ reached getOption(&quot;max.print&quot;) -- omitted 50 entries ] cutree(hcl, h = 3.9) ## [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [36] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 3 2 3 2 3 2 3 3 3 3 2 3 2 3 3 2 3 ## [71] 2 3 2 2 2 2 2 2 2 3 3 3 3 2 3 2 2 2 3 3 3 2 3 3 3 3 3 2 3 3 ## [ reached getOption(&quot;max.print&quot;) -- omitted 50 entries ] identical(cutree(hcl, k = 3), cutree(hcl, h = 3.9)) ## [1] TRUE Challenge Using the same value k = 3, verify if k-means and hierarchical clustering produce the same results on the iris data. Which one, if any, is correct? km &lt;- kmeans(iris[, 1:4], centers = 3, nstart = 10) hcl &lt;- hclust(dist(iris[, 1:4])) table(km$cluster, cutree(hcl, k = 3)) ## ## 1 2 3 ## 1 0 38 0 ## 2 50 0 0 ## 3 0 34 28 par(mfrow = c(1, 2)) plot(iris$Petal.Length, iris$Sepal.Length, col = km$cluster, main = &quot;k-means&quot;) plot(iris$Petal.Length, iris$Sepal.Length, col = cutree(hcl, k = 3), main = &quot;Hierarchical clustering&quot;) ## Checking with the labels provided with the iris data table(iris$Species, km$cluster) ## ## 1 2 3 ## setosa 0 50 0 ## versicolor 2 0 48 ## virginica 36 0 14 table(iris$Species, cutree(hcl, k = 3)) ## ## 1 2 3 ## setosa 50 0 0 ## versicolor 0 23 27 ## virginica 0 49 1 4.5 Principal component analysis (PCA) In R, we can use the prcomp function. Let’s explore PCA on the iris data. While it contains only 4 variables, is already becomes difficult to visualise the 3 groups along all these dimensions. pairs(iris[, -5], col = iris[, 5], pch = 19) Let’s use PCA to reduce the dimension. irispca &lt;- prcomp(iris[, -5]) summary(irispca) ## Importance of components: ## PC1 PC2 PC3 PC4 ## Standard deviation 2.0563 0.49262 0.2797 0.15439 ## Proportion of Variance 0.9246 0.05307 0.0171 0.00521 ## Cumulative Proportion 0.9246 0.97769 0.9948 1.00000 A summary of the prcomp output shows that along PC1 along, we are able to retain over 92% of the total variability in the data. Figure 4.8: Iris data along PC1. 4.5.1 Visualisation A biplot features all original points re-mapped (rotated) along the first two PCs as well as the original features as vectors along the same PCs. Feature vectors that are in the same direction in PC space are also correlated in the original data space. biplot(irispca) One important piece of information when using PCA is the proportion of variance explained along the PCs, in particular when dealing with high dimensional data, as PC1 and PC2 (that are generally used for visualisation), might only account for an insufficient proportion of variance to be relevant on their own. In the code chunk below, I extract the standard deviations from the PCA result to calculate the variances, then obtain the percentage of and cumulative variance along the PCs. var &lt;- irispca$sdev^2 (pve &lt;- var/sum(var)) ## [1] 0.924618723 0.053066483 0.017102610 0.005212184 cumsum(pve) ## [1] 0.9246187 0.9776852 0.9947878 1.0000000 Challenge Repeat the PCA analysis on the iris dataset above, reproducing the biplot and preparing a barplot of the percentage of variance explained by each PC. It is often useful to produce custom figures using the data coordinates in PCA space, which can be accessed as x in the prcomp object. Reproduce the PCA plots below, along PC1 and PC2 and PC3 and PC4 respectively. par(mfrow = c(1, 2)) plot(irispca$x[, 1:2], col = iris$Species) plot(irispca$x[, 3:4], col = iris$Species) "],
["interactive-visualisation.html", "Chapter 5 Interactive visualisation 5.1 Interactivity graphs 5.2 Interactive apps", " Chapter 5 Interactive visualisation 5.1 Interactivity graphs This section is based on the on-line ggvis documentation The goal of ggvis is to make it easy to build interactive graphics for exploratory data analysis. ggvis has a similar underlying theory to ggplot2 (the grammar of graphics), but it’s expressed a little differently, and adds new features to make your plots interactive. ggvis also incorporates shiny’s reactive programming model and dplyr’s grammar of data transformation. library(&quot;ggvis&quot;) sml &lt;- sample(nrow(surveys), 1e3) surveys_sml &lt;- surveys_complete[sml, ] p &lt;- ggvis(surveys_sml, x = ~weight, y = ~hindfoot_length) p %&gt;% layer_points() surveys_sml %&gt;% ggvis(x = ~weight, y = ~hindfoot_length, fill = ~species_id) %&gt;% layer_points() p %&gt;% layer_points(fill = ~species_id) p %&gt;% layer_points(shape = ~species_id) To set fixed plotting parameters, use :=. p %&gt;% layer_points(fill := &quot;red&quot;, stroke := &quot;black&quot;) p %&gt;% layer_points(size := 300, opacity := 0.4) p %&gt;% layer_points(shape := &quot;cross&quot;) 5.1.1 Interactivity p %&gt;% layer_points( size := input_slider(10, 100), opacity := input_slider(0, 1)) p %&gt;% layer_points() %&gt;% add_tooltip(function(df) df$weight) input_slider() input_checkbox() input_checkboxgroup() input_numeric() input_radiobuttons() input_select() input_text() See the interactivity vignette for details. 5.1.2 Layers Simple layers layer_points(), with properties x, y, shape, stroke, fill, strokeOpacity, fillOpacity, and opacity. layer_paths(), for paths and polygons (using the fill argument). layer_ribbons() for filled areas. layer_rects(), layer_text(). Compound layers, which which combine data transformations with one or more simple layers. layer_lines() which automatically orders by the x variable with arrange(). layer_histograms() and layer_freqpolys(), which first bin the data with compute_bin(). layer_smooths(), which fits and plots a smooth model to the data using compute_smooth(). See the layers vignette for details. Like for ggplot2’s geoms, we can overly multiple layers: p %&gt;% layer_points() %&gt;% layer_smooths(stroke := &quot;red&quot;) 5.1.3 More components scales, to control the mapping between data and visual properties; see the properties and scales vignette. legends and axes to control the appearance of the guides produced by the scales. See the axes and legends vignette. 5.2 Interactive apps From the shiny package website: Shiny is an R package that makes it easy to build interactive web apps straight from R. When using shiny, one tends to aim for more complete, long-lasting applications, rather then simply and transient visualisations. A shiny application is composed of a ui (user interface) and a server that exchange information using a programming paradigm called reactive programming: changes performed by the user to the ui trigger a reaction by the server and the output is updated accordingly. Before looking at the details of such an architecture, let’s build a simple example from scratch. This app, shown below, uses the faithful data, describing the wainting time between eruptions and the duration of the reuption for the Old Faithful geyser in Yellowstone National Park, Wyoming, USA. head(faithful) ## eruptions waiting ## 1 3.600 79 ## 2 1.800 54 ## 3 3.333 74 ## 4 2.283 62 ## 5 4.533 85 ## 6 2.883 55 It shows the distribution of waiting times along a histogram (produced by the hist function) and provides a slider to adjust the number of bins (the breaks argument to hist). 5.2.1 Creation of our fist shiny app Create a directory that will contain the app, such as for example &quot;shinyapp&quot;. In this directory, create the ui and server files, named ui.R and server.R. In the ui.R file, copy and paste the following code, that defines a the general UI containing a titel panel with a page title; a page with a sidebar layout, containing a sidebar and a main panel; the sidebar panel contains a slider defining the bins variable (ranging from 1 to 50 with default value of 30); the main panel that plots the distPlot figure. library(shiny) # Define UI for application that draws a histogram shinyUI(fluidPage( # Application title titlePanel(&quot;Hello Shiny!&quot;), # Sidebar with a slider input for the number of bins sidebarLayout( sidebarPanel( sliderInput(&quot;bins&quot;, &quot;Number of bins:&quot;, min = 1, max = 50, value = 30) ), # Show a plot of the generated distribution mainPanel( plotOutput(&quot;distPlot&quot;) ) ) )) In the server.R file, copy and paste the following code, that defines the server backend the server is a function that manages an input and an ouput; the input is the bins defined in the ui that can be accessed with input$bins; the outputs are created by assigning output$distPlot a value with a render functon (here renderPlot). library(shiny) # Define server logic required to draw a histogram shinyServer(function(input, output) { # Expression that generates a histogram. The expression is # wrapped in a call to renderPlot to indicate that: # # 1) It is &quot;reactive&quot; and therefore should be automatically # re-executed when inputs change # 2) Its output type is a plot output$distPlot &lt;- renderPlot({ x &lt;- faithful[, 2] # Old Faithful Geyser data bins &lt;- seq(min(x), max(x), length.out = input$bins + 1) # draw the histogram with the specified number of bins hist(x, breaks = bins, col = &#39;darkgray&#39;, border = &#39;white&#39;) }) }) Run the app with shiny::runApp(&quot;shinyapp&quot;) or simply shiny::runApp() of your working directory is the app dir. Challenge Run your shinyapp application, as described above. "]
]
